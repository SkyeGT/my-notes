name: Deploy to GitHub Pages

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Build job
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Pages
        uses: actions/configure-pages@v4
        
      - name: Process Markdown files
        run: |
          # Create a script to process markdown files and generate data.js
          cat > process_notes.py << 'EOF'
          import os
          import json
          import re
          from pathlib import Path
          
          def extract_frontmatter_and_content(content):
              """Extract frontmatter and content from markdown"""
              lines = content.split('\n')
              
              # Look for status and tags in the first few lines
              status = ''
              tags = []
              
              for i, line in enumerate(lines[:10]):
                  if line.startswith('Status:'):
                      status = line.replace('Status:', '').strip()
                  elif 'Tags:' in line:
                      # Extract tags from [[tag]] format
                      tag_matches = re.findall(r'\[\[([^\]]+)\]\]', line)
                      tags.extend(tag_matches)
              
              return status, tags, content
          
          def extract_links(content):
              """Extract internal links from markdown content"""
              links = re.findall(r'\[\[([^\]]+)\]\]', content)
              return [link + '.md' for link in links]
          
          def process_notes():
              notes = {}
              
              # Define folders to process
              folders_to_process = ['3-Tags', '6-Full Notes', '1-Rough Notes', '2-Source Materials', '4-Indexes']
              
              for folder in folders_to_process:
                  folder_path = Path(folder)
                  if folder_path.exists():
                      for md_file in folder_path.glob('*.md'):
                          try:
                              with open(md_file, 'r', encoding='utf-8') as f:
                                  content = f.read()
                              
                              status, tags, full_content = extract_frontmatter_and_content(content)
                              links = extract_links(content)
                              
                              # Extract title from filename or first heading
                              title = md_file.stem
                              first_heading = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
                              if first_heading:
                                  title = first_heading.group(1)
                              
                              notes[md_file.name] = {
                                  'title': title,
                                  'content': full_content,
                                  'tags': tags,
                                  'status': status,
                                  'folder': folder,
                                  'links': links
                              }
                          except Exception as e:
                              print(f"Error processing {md_file}: {e}")
              
              return notes
          
          # Process notes and generate JavaScript data file
          notes_data = process_notes()
          
          # Generate data.js file
          with open('data.js', 'w', encoding='utf-8') as f:
              f.write('window.NOTES_DATA = ')
              f.write(json.dumps(notes_data, ensure_ascii=False, indent=2))
              f.write(';\n')
          
          print(f"Processed {len(notes_data)} notes")
          EOF
          
          python process_notes.py
        
      - name: Update script.js to use data.js
        run: |
          # Update script.js to load notes from data.js instead of hardcoded data
          sed -i 's/async loadNotes() {/async loadNotes() {\n        if (window.NOTES_DATA) {\n            Object.entries(window.NOTES_DATA).forEach(([filename, note]) => {\n                this.notes.set(filename, note);\n            });\n            this.buildLinks();\n            return;\n        }/' script.js
        
      - name: Add data.js to index.html
        run: |
          # Add data.js script tag before script.js
          sed -i 's|<script src="script.js"></script>|<script src="data.js"></script>\n    <script src="script.js"></script>|' index.html
        
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'

  # Deployment job
  deploy:
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4